import tensorflow as tf
# from tensorflow.keras.models import load_model

import keras
from keras import ops
import numpy as np
import string

chars = list(string.ascii_lowercase + string.digits + " ")
char2idx = {ch: i + 1 for i, ch in enumerate(chars)}  # reserve 0 for padding
vocab_size = len(char2idx) + 1


def preprocess(text, maxlen=20):
    text = text.lower()
    seq = [char2idx.get(ch, 0) for ch in text]
    seq = seq[:maxlen] + [0]*(maxlen - len(seq))
    return np.array(seq)


def analyze_text(text, model):
    input_seq = preprocess(text)
    pred = model.predict(np.expand_dims(input_seq, axis=0), verbose=0)[0]

    print(pred)

    return {
        "input": text,
        "percent_string": round(pred[0]*100, 2),
        "percent_number": round(pred[1]*100, 2)
    }


model = keras.models.load_model("./string_number_classifier.keras")

examples = [
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
    ("h1", [0.5, 0.5]),
    ("", [0.0, 0.0]),
    ("1234567890", [0.0, 1.0]),
    ("0987654321", [0.0, 1.0]),
    ("h3110", [0.6, 0.4]),
    ("789", [0.0, 1.0]),
    ("AA000", [0.4, 0.6]),
    ("A2B1", [0.5, 0.5]),
    ("123lll123", [0.33, 0.66]),
    ("1amb", [0.75, 0.25]),
    ("155b", [0.25, 0.75]),
]

x = np.array([preprocess(text) for text, _ in examples])
y = np.array([label for _, label in examples])

opt1 = tf.keras.optimizers.Adam(learning_rate=1e-3)
opt2 = tf.keras.optimizers.SGD(learning_rate=0.2)

opt_layer_pairs = [(opt1, model.layers[0]), (opt2, model.layers[1])]

loss = tf.keras.losses.MSE

optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)
model.compile(optimizer=optimizer, loss='mse')

model.fit(x, y, batch_size=8, epochs=10, verbose=0)

print(analyze_text(text="Hello", model=model))
print(analyze_text(text="h3110", model=model))
print(analyze_text(text="123456", model=model))
print(analyze_text(text="AI2025", model=model))
print(analyze_text(text="A", model=model))

model.save("string_number_classifier2.keras")
