{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda53627",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1bad16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from googlesearch import search\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "# import mlflow.skilearn\n",
    "\n",
    "model_path = \"../model/code/exports/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c00727",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43c1b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model ==========\n",
      "Type: <class 'sklearn.svm._classes.SVC'>\n",
      "Class: SVC\n",
      "Features expected: 21\n",
      "Classes: [0 1 2 3]\n",
      "Number of classes: 4\n",
      "Support vectors shape: (80117, 21)\n",
      "Number of support vectors per class: [28128 10846  7482 33661]\n",
      "\n",
      "========== Parameter ==========\n",
      "C: 1.0\n",
      "break_ties: False\n",
      "cache_size: 200\n",
      "class_weight: None\n",
      "coef0: 0.0\n",
      "decision_function_shape: ovr\n",
      "degree: 3\n",
      "gamma: scale\n",
      "kernel: rbf\n",
      "max_iter: -1\n",
      "probability: True\n",
      "random_state: 42\n",
      "shrinking: True\n",
      "tol: 0.001\n",
      "verbose: False\n",
      "\n",
      "========== Test Predict ==========\n",
      "Dummy data shape: (1, 21)\n",
      "Sample of dummy data: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and analyze model\n",
    "model = joblib.load(model_path + \"/best_svm_model.pkl\")\n",
    "print(f\"========== Model ==========\")\n",
    "print(f\"Type: {type(model)}\")\n",
    "print(f\"Class: {model.__class__.__name__}\")\n",
    "print(f\"Features expected: {model.n_features_in_}\")\n",
    "print(f\"Classes: {model.classes_}\")\n",
    "print(f\"Number of classes: {len(model.classes_)}\")\n",
    "print(f\"Support vectors shape: {model.support_vectors_.shape}\")\n",
    "print(f\"Number of support vectors per class: {model.n_support_}\")\n",
    "\n",
    "print(f\"\\n========== Parameter ==========\")\n",
    "params = model.get_params()\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36cadc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: rbf\n",
      "Gamma: scale\n",
      "C (regularization): 1.0\n",
      "Probability estimation: True\n",
      "Decision function shape: ovr\n"
     ]
    }
   ],
   "source": [
    "print(f\"Kernel: {model.kernel}\")\n",
    "print(f\"Gamma: {model.gamma}\")\n",
    "print(f\"C (regularization): {model.C}\")\n",
    "print(f\"Probability estimation: {model.probability}\")\n",
    "print(f\"Decision function shape: {model.decision_function_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6273fb",
   "metadata": {},
   "source": [
    "### Avaliable Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "feac76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'break_ties', 'cache_size', 'class_weight', 'class_weight_', 'classes_', 'coef0', 'coef_', 'decision_function', 'decision_function_shape', 'degree', 'dual_coef_', 'epsilon', 'fit', 'fit_status_', 'gamma', 'get_metadata_routing', 'get_params', 'intercept_', 'kernel', 'max_iter', 'n_features_in_', 'n_iter_', 'n_support_', 'nu', 'predict', 'predict_log_proba', 'predict_proba', 'probA_', 'probB_', 'probability', 'random_state', 'score', 'set_fit_request', 'set_params', 'set_score_request', 'shape_fit_', 'shrinking', 'support_', 'support_vectors_', 'tol', 'unused_param', 'verbose']\n"
     ]
    }
   ],
   "source": [
    "methods = [method for method in dir(model) if not method.startswith('_')]\n",
    "print(methods)\n",
    "\n",
    "# for method in dir(model):\n",
    "#   if not method.startswith('_'):\n",
    "#     print(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d747b",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7edf7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from googlesearch import search\n",
    "import numpy as np\n",
    "\n",
    "class FeatureExtraction:\n",
    "    def __init__(self, url: str):\n",
    "        self.url = url\n",
    "        self.parsed = urlparse(url)\n",
    "        self.hostname = str(self.parsed.hostname) if self.parsed.hostname else \"\"\n",
    "        self.tld = self.hostname.split('.')[-1] if '.' in self.hostname else \"\"\n",
    "\n",
    "    def having_ip_address(self):\n",
    "      match = re.search(\n",
    "          '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "          '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "          '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
    "          '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', self.url)  # Ipv6\n",
    "      \n",
    "      if match:\n",
    "          return 1\n",
    "      else:\n",
    "          return 0\n",
    "\n",
    "    def abnormal_url(self):\n",
    "        return 1 if re.search(self.hostname, self.url) else 0\n",
    "\n",
    "    def google_index(self):\n",
    "        try:\n",
    "            site = search(self.url, num_results=5)\n",
    "            return 1 if site else 0\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    def count_dot(self):\n",
    "        return self.url.count('.')\n",
    "\n",
    "    def count_www(self):\n",
    "        return self.url.count(\"www\")\n",
    "\n",
    "    def count_atrate(self):\n",
    "        return self.url.count('@')\n",
    "\n",
    "    def no_of_dir(self):\n",
    "        return self.parsed.path.count('/')\n",
    "\n",
    "    def no_of_embed(self):\n",
    "        return self.parsed.path.count('//')\n",
    "\n",
    "    def suspicious_words(self):\n",
    "        match = re.search(r'PayPal|login|signin|bank|account|update|free|lucky|service|bonus|ebayisapi|webscr',\n",
    "                          self.url, re.IGNORECASE)\n",
    "        return 1 if match else 0\n",
    "\n",
    "    def shortening_service(self):\n",
    "        match = re.search(r'bit\\.ly|goo\\.gl|shorte\\.st|x\\.co|ow\\.ly|t\\.co|tinyurl|is\\.gd|'\n",
    "                          r'cli\\.gs|yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|'\n",
    "                          r'snipurl\\.com|short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|'\n",
    "                          r'qr\\.ae|adf\\.ly|bitly\\.com|cur\\.lv|ity\\.im|q\\.gs|po\\.st|'\n",
    "                          r'bc\\.vc|j\\.mp|cutt\\.us|u\\.bb|v\\.gd|tr\\.im|link\\.zip\\.net',\n",
    "                          self.url)\n",
    "        return 1 if match else 0\n",
    "\n",
    "    def count_https(self):\n",
    "        return self.url.count(\"https\")\n",
    "\n",
    "    def count_http(self):\n",
    "        return self.url.count(\"http\")\n",
    "\n",
    "    def count_per(self):\n",
    "        return self.url.count('%')\n",
    "\n",
    "    def count_ques(self):\n",
    "        return self.url.count('?')\n",
    "\n",
    "    def count_hyphen(self):\n",
    "        return self.url.count('-')\n",
    "\n",
    "    def count_equal(self):\n",
    "        return self.url.count('=')\n",
    "\n",
    "    def url_length(self):\n",
    "        return len(self.url)\n",
    "\n",
    "    def hostname_length(self):\n",
    "        return len(self.parsed.netloc)\n",
    "\n",
    "    def fd_length(self):\n",
    "        try:\n",
    "            return len(self.parsed.path.split('/')[1])\n",
    "        except IndexError:\n",
    "            return 0\n",
    "\n",
    "    def tld_length(self):\n",
    "        return len(self.tld) if self.tld else 0\n",
    "\n",
    "    def digit_count(self):\n",
    "        return sum(c.isdigit() for c in self.url)\n",
    "\n",
    "    def letter_count(self):\n",
    "        return sum(c.isalpha() for c in self.url)\n",
    "\n",
    "    def get_features(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary of features matching the desired list for the model.\n",
    "        \"\"\"\n",
    "        features = {\n",
    "            \"use_of_ip\": self.having_ip_address(),\n",
    "            \"abnormal_url\": self.abnormal_url(),\n",
    "            \"count_.\": self.count_dot(),\n",
    "            \"count_www\": self.count_www(),\n",
    "            \"count_@\": self.count_atrate(),\n",
    "            \"count_dir\": self.no_of_dir(),\n",
    "            \"count_embed_domain\": self.no_of_embed(),\n",
    "            \"short_url\": self.shortening_service(),\n",
    "            \"count%\": self.count_per(),\n",
    "            \"count?\": self.count_ques(),\n",
    "            \"count-\": self.count_hyphen(),\n",
    "            \"count=\": self.count_equal(),\n",
    "            \"url_length\": self.url_length(),\n",
    "            \"count_https\": self.count_https(),\n",
    "            \"count_http\": self.count_http(),\n",
    "            \"hostname_length\": self.hostname_length(),\n",
    "            \"sus_url\": self.suspicious_words(),\n",
    "            \"fd_length\": self.fd_length(),\n",
    "            \"tld_length\": self.tld_length(),\n",
    "            \"count_digits\": self.digit_count(),\n",
    "            \"count_letters\": self.letter_count()\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def get_feature_array(self) -> np.ndarray:\n",
    "        feature_dict = self.get_features()\n",
    "        \n",
    "        feature_order = [\n",
    "            'use_of_ip', 'abnormal_url', 'count_.', 'count_www', 'count_@', 'count_dir', \n",
    "            'count_embed_domain', 'short_url', 'count%', 'count?', 'count-', 'count=', \n",
    "            'url_length', 'count_https', 'count_http', 'hostname_length', 'sus_url', \n",
    "            'fd_length', 'tld_length', 'count_digits', 'count_letters'\n",
    "        ]\n",
    "        \n",
    "        feature_values = [feature_dict[key] for key in feature_order]\n",
    "        \n",
    "        return np.array(feature_values, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FeatureExtraction(url={self.url})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8056ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureExtraction(url=http://example.com/login?user=test)\n",
      "{'use_of_ip': 0, 'abnormal_url': 1, 'count_.': 1, 'count_www': 0, 'count_@': 0, 'count_dir': 1, 'count_embed_domain': 0, 'short_url': 0, 'count%': 0, 'count?': 1, 'count-': 0, 'count=': 1, 'url_length': 34, 'count_https': 0, 'count_http': 1, 'hostname_length': 11, 'sus_url': 1, 'fd_length': 5, 'tld_length': 3, 'count_digits': 0, 'count_letters': 27}\n",
      "[[ 0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1. 34.  0.  1. 11.  1.  5.\n",
      "   3.  0. 27.]]\n"
     ]
    }
   ],
   "source": [
    "url = \"http://example.com/login?user=test\"\n",
    "features = FeatureExtraction(url)\n",
    "\n",
    "print(features)\n",
    "print(features.get_features())\n",
    "print(features.get_feature_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4e510",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de1dd3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Test Predict ==========\n",
      "Dummy data shape: (1, 21)\n",
      "Sample of dummy data: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n========== Test Predict ==========\")\n",
    "\n",
    "n_features = model.n_features_in_\n",
    "dummy_data = np.zeros((1, n_features))\n",
    "\n",
    "print(f\"Dummy data shape: {dummy_data.shape}\")\n",
    "print(f\"Sample of dummy data: {dummy_data}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cabfbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction: 0\n",
      "Predicable: Benign\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # isMalicious\n",
    "    # label_mapping = {\n",
    "    #     0: False,\n",
    "    #     1: True\n",
    "    # }\n",
    "\n",
    "    label_mapping = {\n",
    "        0: \"Benign\",\n",
    "        1: \"Defacement\",\n",
    "        2: \"Malware\",\n",
    "        3: \"Phishing\"\n",
    "    }\n",
    "\n",
    "    prediction = model.predict(dummy_data)[0]\n",
    "    feature_label = label_mapping.get(prediction)\n",
    "\n",
    "    print(f\"Test prediction: {prediction}\")\n",
    "    print(f\"Predicable: {feature_label}\")\n",
    "\n",
    "    # if hasattr(model, 'predict_proba'):\n",
    "    #     try:\n",
    "    #         probabilities = model.predict_proba(dummy_data)\n",
    "    #         print(f\"Prediction probabilities: {probabilities[0]}\")\n",
    "    #         print(\"Class probabilities:\")\n",
    "    #         for i, prob in enumerate(probabilities[0]):\n",
    "    #             print(f\"  Class {model.classes_[i]}: {prob:.4f}\")\n",
    "    #     except Exception as prob_error:\n",
    "    #         print(f\"Probability prediction error: {prob_error}\")\n",
    "            \n",
    "    # if hasattr(model, 'decision_function'):\n",
    "    #     try:\n",
    "    #         decision_scores = model.decision_function(dummy_data)\n",
    "    #         print(f\"Decision function scores: {decision_scores[0]}\")\n",
    "    #         print(\"Decision scores per class:\")\n",
    "    #         for i, score in enumerate(decision_scores[0]):\n",
    "    #             print(f\"  Class {model.classes_[i]}: {score:.4f}\")\n",
    "    #     except Exception as dec_error:\n",
    "    #         print(f\"Decision function error: {dec_error}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Prediction error: {e}\")\n",
    "    print(f\"Error type: {type(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
