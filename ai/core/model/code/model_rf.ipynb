{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f2f51d",
   "metadata": {},
   "source": [
    "# URL Classification with Random Forest\n",
    "This notebook implements URL classification (malicious URL detection) using Random Forest algorithm.\n",
    "It includes comprehensive feature engineering and model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e00565",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4787f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from tld import get_tld\n",
    "import os.path\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "from wordcloud import WordCloud\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648d9be",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv('../artifacts/dataset/malicious_phish.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nDataset head:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b94f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and null values\n",
    "print(\"Data Info:\")\n",
    "df.info()\n",
    "print(\"\\nNull values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a31c7",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "All feature engineering functions are preserved from the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15e980",
   "metadata": {},
   "source": [
    "### 3.1 IP Address Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of IP or not in domain\n",
    "def having_ip_address(url):\n",
    "    match = re.search(\n",
    "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
    "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n",
    "    \n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['use_of_ip'] = df['url'].apply(lambda i: having_ip_address(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed068bf5",
   "metadata": {},
   "source": [
    "### 3.2 Abnormal URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abnormal_url(url):\n",
    "    hostname = urlparse(url).hostname\n",
    "    hostname = str(hostname)\n",
    "    match = re.search(hostname, url)\n",
    "    if match:      \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['abnormal_url'] = df['url'].apply(lambda i: abnormal_url(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbbd35",
   "metadata": {},
   "source": [
    "### 3.3 Google Index (Simplified for performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified google_index - set all to 1 for performance\n",
    "# In production, you would use actual Google Search API\n",
    "df['google_index'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95035c55",
   "metadata": {},
   "source": [
    "### 3.4 Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51040e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count dot (.)\n",
    "def count_dot(url):\n",
    "    count_dot = url.count('.')\n",
    "    return count_dot\n",
    "\n",
    "df['count.'] = df['url'].apply(lambda i: count_dot(i))\n",
    "\n",
    "# Count www\n",
    "def count_www(url):\n",
    "    url.count('www')\n",
    "    return url.count('www')\n",
    "\n",
    "df['count-www'] = df['url'].apply(lambda i: count_www(i))\n",
    "\n",
    "# Count @\n",
    "def count_atrate(url):\n",
    "    return url.count('@')\n",
    "\n",
    "df['count@'] = df['url'].apply(lambda i: count_atrate(i))\n",
    "\n",
    "# Count directories\n",
    "def no_of_dir(url):\n",
    "    urldir = urlparse(url).path\n",
    "    return urldir.count('/')\n",
    "\n",
    "df['count_dir'] = df['url'].apply(lambda i: no_of_dir(i))\n",
    "\n",
    "# Count embedded domains\n",
    "def no_of_embed(url):\n",
    "    urldir = urlparse(url).path\n",
    "    return urldir.count('//')\n",
    "\n",
    "df['count_embed_domain'] = df['url'].apply(lambda i: no_of_embed(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955006c7",
   "metadata": {},
   "source": [
    "### 3.5 Suspicious Words Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41fd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suspicious_words(url):\n",
    "    match = re.search('PayPal|login|signin|bank|account|update|free|lucky|service|bonus|ebayisapi|webscr',\n",
    "                      url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['sus_url'] = df['url'].apply(lambda i: suspicious_words(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbfb40",
   "metadata": {},
   "source": [
    "### 3.6 URL Shortening Service Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortening_service(url):\n",
    "    match = re.search(r'bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                      r'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                      r'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                      r'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                      r'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                      r'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                      r'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                      r'tr\\.im|link\\.zip\\.net',\n",
    "                      url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['short_url'] = df['url'].apply(lambda i: shortening_service(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d6c82",
   "metadata": {},
   "source": [
    "### 3.7 Protocol Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b2729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count https\n",
    "def count_https(url):\n",
    "    return url.count('https')\n",
    "\n",
    "df['count_https'] = df['url'].apply(lambda i: count_https(i))\n",
    "\n",
    "# Count http\n",
    "def count_http(url):\n",
    "    return url.count('http')\n",
    "\n",
    "df['count_http'] = df['url'].apply(lambda i: count_http(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ef566",
   "metadata": {},
   "source": [
    "### 3.8 Special Character Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count %\n",
    "def count_per(url):\n",
    "    return url.count('%')\n",
    "\n",
    "df['count%'] = df['url'].apply(lambda i: count_per(i))\n",
    "\n",
    "# Count ?\n",
    "def count_ques(url):\n",
    "    return url.count('?')\n",
    "\n",
    "df['count?'] = df['url'].apply(lambda i: count_ques(i))\n",
    "\n",
    "# Count -\n",
    "def count_hyphen(url):\n",
    "    return url.count('-')\n",
    "\n",
    "df['count-'] = df['url'].apply(lambda i: count_hyphen(i))\n",
    "\n",
    "# Count =\n",
    "def count_equal(url):\n",
    "    return url.count('=')\n",
    "\n",
    "df['count='] = df['url'].apply(lambda i: count_equal(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618b690",
   "metadata": {},
   "source": [
    "### 3.9 Length Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL length\n",
    "def url_length(url):\n",
    "    return len(str(url))\n",
    "\n",
    "df['url_length'] = df['url'].apply(lambda i: url_length(i))\n",
    "\n",
    "# Hostname length\n",
    "def hostname_length(url):\n",
    "    return len(urlparse(url).netloc)\n",
    "\n",
    "df['hostname_length'] = df['url'].apply(lambda i: hostname_length(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f783d",
   "metadata": {},
   "source": [
    "### 3.10 Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First directory length\n",
    "def fd_length(url):\n",
    "    urlpath = urlparse(url).path\n",
    "    try:\n",
    "        return len(urlpath.split('/')[1])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "df['fd_length'] = df['url'].apply(lambda i: fd_length(i))\n",
    "\n",
    "# TLD length\n",
    "def tld_length(tld):\n",
    "    try:\n",
    "        return len(tld)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "df['tld'] = df['url'].apply(lambda i: get_tld(i, fail_silently=True))\n",
    "df['tld_length'] = df['tld'].apply(lambda i: tld_length(i))\n",
    "df = df.drop(\"tld\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c96ee02",
   "metadata": {},
   "source": [
    "### 3.11 Character Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44404d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count digits\n",
    "def digit_count(url):\n",
    "    digits = 0\n",
    "    for i in url:\n",
    "        if i.isnumeric():\n",
    "            digits = digits + 1\n",
    "    return digits\n",
    "\n",
    "df['count_digits'] = df['url'].apply(lambda i: digit_count(i))\n",
    "\n",
    "# Count letters\n",
    "def letter_count(url):\n",
    "    letters = 0\n",
    "    for i in url:\n",
    "        if i.isalpha():\n",
    "            letters = letters + 1\n",
    "    return letters\n",
    "\n",
    "df['count_letters'] = df['url'].apply(lambda i: letter_count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b9732",
   "metadata": {},
   "source": [
    "## 4. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['type_code'] = label_encoder.fit_transform(df['type'])\n",
    "\n",
    "print(\"Label mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{label}: {i}\")\n",
    "\n",
    "print(\"\\nTarget distribution after encoding:\")\n",
    "print(df['type_code'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb832d5",
   "metadata": {},
   "source": [
    "## 5. Feature and Target Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix X and target vector Y\n",
    "X = df[['use_of_ip','abnormal_url', 'count.', 'count-www', 'count@',\n",
    "       'count_dir', 'count_embed_domain', 'short_url', 'count%', 'count?', \n",
    "       'count-', 'count=', 'url_length', 'count_https', 'count_http', \n",
    "       'hostname_length', 'sus_url', 'fd_length', 'tld_length', 'count_digits',\n",
    "       'count_letters']]\n",
    "\n",
    "Y = df['type_code']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {Y.shape}\")\n",
    "print(f\"\\nFeatures: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216c495",
   "metadata": {},
   "source": [
    "## 6. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "print(Y_train.value_counts())\n",
    "print(f\"\\nTest target distribution:\")\n",
    "print(Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4afb5",
   "metadata": {},
   "source": [
    "## 7. Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest with basic parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model.fit(X_train, Y_train)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0509a4",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "Y_pred_train = rf_model.predict(X_train)\n",
    "Y_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_accuracy = accuracy_score(Y_train, Y_pred_train) * 100\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred_test) * 100\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Classification Report (Test Set)\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(Y_test, Y_pred_test, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0bf87",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de07256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix - Random Forest', fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix values\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0ed78",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ba807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importances['feature'][:15], feature_importances['importance'][:15])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances - Random Forest', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importances.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bad4b3",
   "metadata": {},
   "source": [
    "## 11. Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_filename = 'best_rf_model.pkl'\n",
    "joblib.dump(rf_model, model_filename)\n",
    "print(f\"Model saved as: {model_filename}\")\n",
    "\n",
    "# Save the label encoder\n",
    "encoder_filename = 'label_encoder_rf.pkl'\n",
    "joblib.dump(label_encoder, encoder_filename)\n",
    "print(f\"Label encoder saved as: {encoder_filename}\")\n",
    "\n",
    "# Save model performance metrics\n",
    "metrics = {\n",
    "    'model': 'Random Forest',\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 'None',\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv('rf_model_metrics.csv', index=False)\n",
    "print(f\"Metrics saved to: rf_model_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6f7d3",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Algorithm: Random Forest Classifier\")\n",
    "print(f\"Number of Trees: 100\")\n",
    "print(f\"Max Depth: None (unlimited)\")\n",
    "print(f\"Number of Features: {X.shape[1]}\")\n",
    "print(f\"Training Samples: {X_train.shape[0]}\")\n",
    "print(f\"Test Samples: {X_test.shape[0]}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  - Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"  - Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"\\nModel saved as: {model_filename}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
